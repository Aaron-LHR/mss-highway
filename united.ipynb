{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T08:52:19.534154Z",
     "start_time": "2022-03-22T08:52:18.739016Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "import seaborn as sns\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import chinese_calendar as calendar  # !pip install chinesecalendar\n",
    "from chinese_calendar import is_workday, is_holiday\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import uuid\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "\n",
    "def to_float16(df):\n",
    "    float64_columns = df.columns[df.dtypes == 'float64']\n",
    "    df[float64_columns] = df[float64_columns].astype(np.float16)\n",
    "    return df\n",
    "\n",
    "def to_int16(df):\n",
    "    int16_columns = df.columns[df.dtypes == 'int64']\n",
    "    df[int16_columns] = df[int16_columns].astype(np.float16)\n",
    "    return df\n",
    "import datetime    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T08:52:20.831762Z",
     "start_time": "2022-03-22T08:52:20.828207Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gbk_data_path = '/home/AI/DATA'\n",
    "\n",
    "year_list = [2018, 2019, 2020]\n",
    "gbk_year_data_name = 'GBK_{}_DATA'\n",
    "\n",
    "\n",
    "user = \"analy\"\n",
    "pwd = \"An@postgres.2020\"\n",
    "host = \"10.3.78.136\"\n",
    "# host = \"10.3.78.134\"\n",
    "port = \"9432\"\n",
    "\n",
    "dbname = \"zwd_predict\"\n",
    "shema = \"ods\"\n",
    "\n",
    "# engine = create_engine('mysql+mysqlconnector://[user]:[pass]@[host]:[port]/[dbname]', echo=False)\n",
    "# 以上为引擎创建格式\n",
    "\n",
    "con = 'postgresql+psycopg2://'+user+':'+pwd+'@'+host+':'+port+'/'+dbname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T01:15:33.425309Z",
     "start_time": "2022-02-17T01:11:53.994179Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#  show_database_sql = \"select datname from pg_database\"\n",
    "# show_tables_sql = \"select tablename from pg_tables where schemaname='ods'order by tablename\"\n",
    "\n",
    "\n",
    "# sql = 'select statis_id, ljpym, stn_name, daoda_time, chufa_time, arr_name, arrival0, depart0, arr_delay, dpt_delay, track, stn_flag,arr_er,dpt_er from ods.\"gbk_kypx_detail_2020_jggt\"'\n",
    "# sql = \"select * from ods.gbk_kypx_detail_2020\"\n",
    "# sql = \"select statis_id, ljpym, stn_name, daoda_time, chufa_time, arr_name, arrival0, depart0, arr_delay, dpt_delay, track, stn_flag  from ods.gbk_kypx_detail_2020 limit 100\"\n",
    "# sql = \"select statis_id, ljpym, stn_name, daoda_time, chufa_time, arr_name, arrival0, depart0, arr_delay, dpt_delay, track, stn_flag  from ods.gbk_kypx_detail_2019 where date_part('month' ,cast (daoda_time as timestamp)) in(\"+part_month+\")\"\n",
    "# sql = \"select  statis_id, ljpym, stn_name, daoda_time, chufa_time, arr_name, arrival0, depart0, arr_delay, dpt_delay, track, stn_flag,xm,arr_er,dpt_er from ods.gbk_kypx_detail_2020_jh  where substring(arr_name, 1 ,1 ) in ('C','D','G') and XM='沪蓉线' order by statis_id,arrival0;\"\n",
    "sql = \"select  statis_id, ljpym, stn_name, daoda_time, chufa_time, arr_name, arrival0, depart0, arr_delay, dpt_delay, track, stn_flag,xm,arr_er,dpt_er from ods.gbk_kypx_detail_2020_jh  where substring(arr_name, 1 ,1 ) in ('C','D','G') and statis_id in (select  distinct   statis_id from ods.gbk_kypx_detail_2020_jh  where substring(arr_name, 1 ,1 ) in ('C','D','G') and XM='沪昆高铁');\"\n",
    "df = pd.read_sql(sql, con)\n",
    "\n",
    "\n",
    "df.columns = [i.upper() for i in df.columns]\n",
    "\n",
    "print(df.info(memory_usage='deep'))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T09:16:51.244609Z",
     "start_time": "2022-01-28T09:16:51.242225Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # (df['ARR_NAME'].str[-1])%2==0\n",
    "# q=df['ARR_NAME'].str[-1]\n",
    "# q=q.astype(int)\n",
    "# df['sx']=q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T09:16:52.681133Z",
     "start_time": "2022-01-28T09:16:52.679407Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # df=df[df['sx']%2==0]\n",
    "# # df\n",
    "# df=df[df['sx']%2==1]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T09:16:54.586624Z",
     "start_time": "2022-01-28T09:16:53.533379Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "s=df[df['STN_NAME'].str[-3:]=='线路所']\n",
    "s=s.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T09:16:55.048058Z",
     "start_time": "2022-01-28T09:16:54.588627Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df=df[~df.index.isin(s)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T01:15:34.102001Z",
     "start_time": "2022-02-17T01:15:33.427894Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "s=df.drop_duplicates(['STATIS_ID'],keep='first')\n",
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T01:15:35.600397Z",
     "start_time": "2022-02-17T01:15:34.104308Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df['jhtz']=np.where(df['ARRIVAL0']>df['DEPART0'],2,np.where(round(\n",
    "    (pd.to_datetime(df['DEPART0']) -\n",
    "     pd.to_datetime(df['ARRIVAL0'])).dt.seconds)>50,1,0))\n",
    "df['sjtz']=np.where(df['DAODA_TIME']>df['CHUFA_TIME'],2,np.where(round(\n",
    "    (pd.to_datetime(df['CHUFA_TIME']) -\n",
    "     pd.to_datetime(df['DAODA_TIME'])).dt.seconds)>50,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T01:15:37.479142Z",
     "start_time": "2022-02-17T01:15:35.602785Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# error=df[(df['jhtz']!=df['sjtz']) & ( (df['STN_FLAG']!='1') & (df['STN_FLAG']!='2') )]\n",
    "error=df[ ((df['jhtz']==2) | (df['sjtz']==2)) & ( (df['STN_FLAG']!='1') & (df['STN_FLAG']!='2') ) ]\n",
    "error.drop_duplicates(['STATIS_ID'],keep='first',inplace=True)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T01:15:40.230650Z",
     "start_time": "2022-02-17T01:15:37.481102Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df=df[~df['STATIS_ID'].isin(error['STATIS_ID'])]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T01:15:42.151458Z",
     "start_time": "2022-02-17T01:15:40.232507Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df=df[(pd.to_datetime(df['DAODA_TIME'])-pd.to_datetime(df['CHUFA_TIME']))<'00:01:40']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T01:15:44.403162Z",
     "start_time": "2022-02-17T01:15:42.153219Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# id_qc=df[((df['ARR_ER']<=5)|(df['DPT_ER']<=5))& ((df['ARR_ER']-df['DPT_ER'])<=20)]\n",
    "id_qc=df[np.abs(df['ARR_ER']<5)|np.abs(df['DPT_ER']<5)]\n",
    "id_qc=id_qc[np.abs(id_qc['ARR_ER']-id_qc['DPT_ER'])>20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T01:15:44.501793Z",
     "start_time": "2022-02-17T01:15:44.406393Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "id_qc.drop_duplicates(['STATIS_ID'],keep='first',inplace=True)\n",
    "len(id_qc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T01:15:47.024426Z",
     "start_time": "2022-02-17T01:15:44.504485Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df=df[~df['STATIS_ID'].isin(id_qc['STATIS_ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T01:15:47.131895Z",
     "start_time": "2022-02-17T01:15:47.026641Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del df['ARR_ER']\n",
    "del df['DPT_ER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T01:15:47.212326Z",
     "start_time": "2022-02-17T01:15:47.134853Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T01:17:13.859763Z",
     "start_time": "2022-02-17T01:15:47.213761Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.groupby('STATIS_ID').filter(lambda x: len(x['ARR_NAME'].values[0]) < 6) \n",
    "df = df[df['ARR_NAME'].map(lambda x: str(x[0]) in 'GD')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T01:17:38.384232Z",
     "start_time": "2022-02-17T01:17:13.863102Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=df.columns[1:],keep='first',inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T01:17:40.828223Z",
     "start_time": "2022-02-17T01:17:38.386064Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bad_id = df[df['STN_NAME'].isnull()]['STATIS_ID'].tolist()\n",
    "df = df[~df['STATIS_ID'].isin(bad_id)]\n",
    "del bad_id\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T01:17:46.775111Z",
     "start_time": "2022-02-17T01:17:40.830114Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T01:17:48.246359Z",
     "start_time": "2022-02-17T01:17:46.778616Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[df['STN_FLAG'] == 0]['ARR_DELAY1'] = 0\n",
    "df[df['STN_FLAG'] == 1]['DPT_DELAY1'] = 0\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T01:33:11.016494Z",
     "start_time": "2022-02-17T01:17:48.248164Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 基于行程ID和到达时间排序\n",
    "df['ARR_DELAY'] = df['ARR_DELAY'] * 60\n",
    "df['DPT_DELAY'] = df['DPT_DELAY'] * 60\n",
    "df.sort_values(['STATIS_ID','DAODA_TIME'], inplace=True, ascending=[True,True])\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 构建\"上一站出发晚点时间\"字段\n",
    "df['LAST_DPT_DELAY']=0\n",
    "for i in range(len(df)):\n",
    "    if i==0:\n",
    "        df['LAST_DPT_DELAY'].iat[i]=0\n",
    "    else:\n",
    "        #print(i)\n",
    "        if df['STATIS_ID'].iat[i]==df['STATIS_ID'].iat[i-1]:\n",
    "            df['LAST_DPT_DELAY'].iat[i]=df['DPT_DELAY'].iat[i-1]\n",
    "        else:\n",
    "            df['LAST_DPT_DELAY'].iat[i]=0\n",
    "#df=df.head(10000)\n",
    "arr_delay_types = ['到达正点','到达初始晚点','到达连带晚点']           \n",
    "dpt_delay_types = ['出发正点','出发初始晚点','出发连带晚点']\n",
    "df['ARR_DELAY_TYPE']='0'\n",
    "df['DPT_DELAY_TYPE']='0'\n",
    "for i in range(len(df)):\n",
    "    if i==0:\n",
    "        if df['ARR_DELAY'].iat[i]>240:\n",
    "            df['ARR_DELAY_TYPE'].iat[i]=arr_delay_types[1]\n",
    "            df['DPT_DELAY_TYPE'].iat[i]=dpt_delay_types[2]\n",
    "        else:\n",
    "            df['ARR_DELAY_TYPE'].iat[i]=arr_delay_types[0]\n",
    "            df['DPT_DELAY_TYPE'].iat[i]=dpt_delay_types[0]\n",
    "    else:\n",
    "       # print(i)\n",
    "        if df['STATIS_ID'].iat[i]==df['STATIS_ID'].iat[i-1]:\n",
    "            if df['DPT_DELAY_TYPE'].iat[i-1]==dpt_delay_types[0]:\n",
    "                if df['ARR_DELAY'].iat[i]>240:\n",
    "                    df['ARR_DELAY_TYPE'].iat[i]=arr_delay_types[1]\n",
    "                else:\n",
    "                    df['ARR_DELAY_TYPE'].iat[i]=arr_delay_types[0]\n",
    "            else:\n",
    "                if df['ARR_DELAY'].iat[i]>0:\n",
    "                    df['ARR_DELAY_TYPE'].iat[i]=arr_delay_types[2]\n",
    "                else:\n",
    "                    df['ARR_DELAY_TYPE'].iat[i]=arr_delay_types[0]          \n",
    "            if df['ARR_DELAY_TYPE'].iat[i]==arr_delay_types[0]:\n",
    "                if df['DPT_DELAY'].iat[i]>240:\n",
    "                    df['DPT_DELAY_TYPE'].iat[i]=dpt_delay_types[1]\n",
    "                else:\n",
    "                    df['DPT_DELAY_TYPE'].iat[i]=dpt_delay_types[0]\n",
    "            else:\n",
    "                if df['DPT_DELAY'].iat[i]>0:\n",
    "                    df['DPT_DELAY_TYPE'].iat[i]=dpt_delay_types[2]\n",
    "                else:\n",
    "                    df['DPT_DELAY_TYPE'].iat[i]=dpt_delay_types[0]\n",
    "        else:\n",
    "            if df['ARR_DELAY'].iat[i]>240:\n",
    "                df['ARR_DELAY_TYPE'].iat[i]=arr_delay_types[1]\n",
    "                df['DPT_DELAY_TYPE'].iat[i]=dpt_delay_types[2]\n",
    "            else:\n",
    "                df['ARR_DELAY_TYPE'].iat[i]=arr_delay_types[0]\n",
    "                df['DPT_DELAY_TYPE'].iat[i]=dpt_delay_types[0]\n",
    "        \n",
    "            \n",
    "    \n",
    "                    \n",
    "            \n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "# df['LAST_DPT_DELAY'] = df['DPT_DELAY'].shift(1)\n",
    "# df['LAST_DPT_DELAY'] = np.where(df['STATIS_ID'].shift(1) == df['STATIS_ID'], df['LAST_DPT_DELAY'], 0)  # 始发站上一站出发晚点时间置0\n",
    "\n",
    "# 构建\"到达晚点类型\"字段\n",
    "#conditions = [df['ARR_DELAY'] == 0, df['ARR_DELAY'] < 0, df['ARR_DELAY'] > 0]\n",
    "#choices = ['到达正点','早到','到达初始晚点']  # 先将晚点全部设为初始晚点，后续再部分更新为连带晚点\n",
    "#df['ARR_DELAY_TYPE'] = np.select(conditions, choices, default='unkown')\n",
    "\n",
    "# 构建\"出发晚点类型\"字段\n",
    "#conditions = [df['DPT_DELAY'] == 0, df['DPT_DELAY'] < 0, df['DPT_DELAY'] > 0]\n",
    "#choices = ['出发正点','早发','出发初始晚点']\n",
    "#df['DPT_DELAY_TYPE'] = np.select(conditions, choices, default='unkown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-02-16T09:02:23.615Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# # 标记\"到达连带晚点\"\n",
    "# index = np.where((df['ARR_DELAY'] > 0) & (df['LAST_DPT_DELAY'] > 0))[0]\n",
    "# df['ARR_DELAY_TYPE'][index] = '到达连带晚点'\n",
    "# df['ARR_DELAY_TYPE'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-01-28T08:41:39.227Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # 标记\"出发连带晚点\"\n",
    "# index = np.where((df['DPT_DELAY'] > 0) & (df['ARR_DELAY'] > 0))[0]\n",
    "# df['DPT_DELAY_TYPE'][index] = '出发连带晚点'\n",
    "# print(df['DPT_DELAY_TYPE'].value_counts())\n",
    "\n",
    "# del df['LAST_DPT_DELAY']  # 删除\"上一站出发晚点时间\"字段\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T01:34:19.971146Z",
     "start_time": "2022-02-17T01:33:11.018949Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.sort_values(['STATIS_ID', 'DAODA_TIME'], inplace=True, ascending=[True, True])\n",
    "\n",
    "df['LJPYM'] = df['LJPYM'].fillna(method='ffill', axis=0)\n",
    "new_col = ['STATIS_ID', 'TYPE']\n",
    "\n",
    "df_type = df.groupby('STATIS_ID')['LJPYM'].nunique().reset_index()\n",
    "df_type.columns = new_col\n",
    "\n",
    "df = pd.merge(df, df_type, on = 'STATIS_ID')\n",
    "df.loc[df['TYPE'] > 1, 'TYPE'] = 'ZT'\n",
    "df.loc[df['TYPE'] == 1, 'TYPE'] = 'GN'\n",
    "\n",
    "del df['LJPYM']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T02:06:06.108933Z",
     "start_time": "2022-02-17T01:34:19.974565Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 当前站到下一站的区间实际运行时间\n",
    "df['SJ_YX_TIME']=0\n",
    "df['TD_YX_TIME']=0\n",
    "for i in range(len(df)):\n",
    "    if i==0:\n",
    "        df['SJ_YX_TIME'].iat[i]=0\n",
    "        df['TD_YX_TIME'].iat[i]=0\n",
    "    else:\n",
    "        print(i)\n",
    "        if df['STATIS_ID'].iat[i]==df['STATIS_ID'].iat[i-1]:\n",
    "#             print(df['DAODA_TIME'].iat[i+1])\n",
    "# #             print(pd.to_datetime(df['DAODA_TIME'].iat[i+1]).time)\n",
    "#             print(pd.to_datetime(df['DAODA_TIME'].iat[i+1])-pd.to_datetime(df['CHUFA_TIME'].iat[i]))\n",
    "            df['SJ_YX_TIME'].iat[i]=(pd.to_datetime(df['DAODA_TIME'].iat[i])-pd.to_datetime(df['CHUFA_TIME'].iat[i-1])).seconds\n",
    "            df['TD_YX_TIME'].iat[i]=(pd.to_datetime(df['ARRIVAL0'].iat[i])-pd.to_datetime(df['DEPART0'].iat[i-1])).seconds\n",
    "        else:\n",
    "            df['SJ_YX_TIME'].iat[i]=0\n",
    "            df['TD_YX_TIME'].iat[i]=0\n",
    "# df['SJ_YX_TIME'] = (pd.to_datetime(df['DAODA_TIME'].shift(-1)) -\n",
    "#                     pd.to_datetime(df['CHUFA_TIME'])).dt.seconds\n",
    "# # 当前站到下一站的区间图定运行时间\n",
    "# df['TD_YX_TIME'] = (pd.to_datetime(df['ARRIVAL0'].shift(-1)) -\n",
    "#                     pd.to_datetime(df['DEPART0'])).dt.seconds\n",
    "# # 标志位，后面用于过滤每条行程的最后一站数据\n",
    "# df['IS_SAME'] = (df['STATIS_ID'].shift(1) == df['STATIS_ID']).shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T02:06:06.232840Z",
     "start_time": "2022-02-17T02:06:06.111074Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['SJ_YX_TIME/TD_YX_TIME']=df['SJ_YX_TIME'] / df['TD_YX_TIME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T02:06:08.879202Z",
     "start_time": "2022-02-17T02:06:06.234573Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ## 对【实际运行时间/计划运行时间】的比值进行四分位数统计\n",
    "\n",
    "# # 过滤每条行程的最后一站数据\n",
    "# # df1 = df[df['IS_SAME'] == True]\n",
    "\n",
    "# df1 = df[['STATIS_ID', 'SJ_YX_TIME', 'TD_YX_TIME','STN_NAME']]\n",
    "# # 增加比值列\n",
    "# df1['SJ_YX_TIME/TD_YX_TIME'] = df1['SJ_YX_TIME'] / df1['TD_YX_TIME']\n",
    "# # 筛选发生了区间吸收的数据\n",
    "# df1 = df1[df1['SJ_YX_TIME/TD_YX_TIME'] >1]\n",
    "# # 计算区间IQR\n",
    "# k = 3\n",
    "# Q1 = df1['SJ_YX_TIME/TD_YX_TIME'].quantile(0.25)\n",
    "# Q3 = df1['SJ_YX_TIME/TD_YX_TIME'].quantile(0.75)\n",
    "# QJ_IQR = round(Q3 + k * (Q3 - Q1), 2)\n",
    "# print('Q1',Q1, 'Q3',Q3, 'QJ_IQR',QJ_IQR)\n",
    "# # 筛选出比值小于IQR的id集合\n",
    "# remove_ids1 = set(df1[df1['SJ_YX_TIME/TD_YX_TIME'] > QJ_IQR]['STATIS_ID'].values)\n",
    "remove_ids1=df[(df['TD_YX_TIME']>=180) &  (df['SJ_YX_TIME/TD_YX_TIME']>=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T02:06:09.165788Z",
     "start_time": "2022-02-17T02:06:08.881040Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df1.drop_duplicates('STATIS_ID',keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T07:13:13.739661Z",
     "start_time": "2022-02-16T07:13:13.738024Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df2 = df[df['STATIS_ID'].isin(remove_ids1)]\n",
    "# df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-02-16T03:20:25.395Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df2[(df2['SJ_YX_TIME/TD_YX_TIME']>1.59)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T02:06:09.173163Z",
     "start_time": "2022-02-17T02:06:09.169759Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(remove_ids1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T02:06:10.066571Z",
     "start_time": "2022-02-17T02:06:09.175118Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "id=df.drop_duplicates('STATIS_ID',keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T02:06:11.970531Z",
     "start_time": "2022-02-17T02:06:10.068229Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df[~df['STATIS_ID'].isin(remove_ids1)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # 过滤区间吸收异常或车站吸收异常的行程\n",
    "# remove_ids = remove_ids1\n",
    "# df = df[~df['STATIS_ID'].isin(remove_ids)]\n",
    "\n",
    "# # 验证，交集应该为空\n",
    "# assert set(df['STATIS_ID'].values) & set(remove_ids) == set()\n",
    "\n",
    "# # 删除无用列\n",
    "# # df.drop(df[['SJ_YX_TIME', 'TD_YX_TIME', 'IS_SAME']], axis=1, inplace=True)\n",
    "# # del df1,df2\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# arr_up_threshold = arr_threshold2\n",
    "# dpt_up_threshold = dpt_threshold2\n",
    "# print('arr_up_threshold:',arr_up_threshold)\n",
    "# print('dpt_up_threshold:',dpt_up_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# id_all = set(df['STATIS_ID'])\n",
    "\n",
    "# set1 = set(df['STATIS_ID'].values[np.where(np.abs(df['ARR_DELAY1'].values) > arr_up_threshold)[0]])\n",
    "# set2 = set(df['STATIS_ID'].values[np.where(np.abs(df['DPT_DELAY1'].values) > dpt_up_threshold)[0]])\n",
    "# id_remove = set1.union(set2)\n",
    "# id_keep = id_all.difference(id_remove)\n",
    "\n",
    "# df = df[df['STATIS_ID'].isin(id_keep)]\n",
    "# assert len(np.where(np.abs(df['ARR_DELAY1'].values) > arr_up_threshold)[0]) + len(np.where(np.abs(df['DPT_DELAY1'].values) > dpt_up_threshold)[0]) == 0\n",
    "\n",
    "# # release\n",
    "# del df_tmp\n",
    "\n",
    "# print(df.columns)\n",
    "# print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df_ajb = pd.read_csv(os.path.join(gbk_data_path, '2020-AJB_DATA.csv'))\n",
    "\n",
    "# df_ajb.dropna(how='any', inplace=True)\n",
    "\n",
    "# print(df_ajb.info())\n",
    "# df_ajb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ids_list = df_ajb['STATIS_ID'].unique().tolist()\n",
    "# print(len(ids_list))\n",
    "\n",
    "# df = df[~df['STATIS_ID'].isin(ids_list)]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df['FORMER_STN']\n",
    "# df['FORMER_STN'] = df['STN_NAME'].shift(1)  # 上一站"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sql = \"select * from ods.zwd_xd_xb\"\n",
    "# df_xlqj = pd.read_sql(sql, con)\n",
    "# print(df_xlqj.shape)\n",
    "\n",
    "# df_xlqj = {(k1,k2): v for k1, k2, v in df_xlqj[['q_czm','h_czm','xm']].values}\n",
    "\n",
    "# def assign_xm(x):\n",
    "#     k1 = x['FORMER_STN']\n",
    "#     k2 = x['STN_NAME']\n",
    "  \n",
    "#     try:\n",
    "#         return df_xlqj[(k1, k2)]\n",
    "#     except:\n",
    "#         try: \n",
    "#             return df_xlqj[(k2, k1)]\n",
    "#         except:\n",
    "#             return '0' \n",
    "\n",
    "        \n",
    "# df['FORMER_STN'] = df['STN_NAME'].shift(1)  # 上一站\n",
    "# df.loc[:, \"xm\"] = df.progress_apply(assign_xm, axis=1)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df1=df\n",
    "# df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # xm_var = df['xm'].unique().tolist()\n",
    "# # xm_var\n",
    "# # print([i for i in xm_var if '京沪' in i ])\n",
    "\n",
    "# # xm = ['京广高速','京广高速京西联']\n",
    "# # df1 = df[df['xm'].map(lambda x: str(x[0:3]) in '京广高速')]\n",
    "# df = df[df['xm'].str[0:4]=='京广高速']\n",
    "# # df = df[(df['xm'] =='京广高速') | (df['xm'] =='京广高速京西联')]\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T02:14:02.285146Z",
     "start_time": "2022-02-17T02:06:11.972023Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def delay_pct(x,var_in,var_out):\n",
    "    totoal_freq = len(x[var_in])\n",
    "    delay_freq = (x[var_in]>0).sum()\n",
    "    x[var_out] = delay_freq/totoal_freq\n",
    "    return x\n",
    "\n",
    "def early_pct(x,var_in,var_out):\n",
    "    totoal_freq = len(x[var_in])\n",
    "    delay_freq = (x[var_in]<0).sum()\n",
    "    x[var_out] = delay_freq/totoal_freq\n",
    "    return x\n",
    "\n",
    "df = df.groupby(['STN_NAME']).apply(delay_pct,'ARR_DELAY','stn_arr_delay_pct')\n",
    "df = df.groupby(['ARR_NAME']).apply(delay_pct,'ARR_DELAY','train_arr_delay_pct')\n",
    "df = df.groupby(['ARR_NAME','STN_NAME']).apply(delay_pct,'ARR_DELAY','stn_train_arr_delay_pct')\n",
    "\n",
    "df = df.groupby(['STN_NAME']).apply(early_pct,'ARR_DELAY','stn_arr_early_pct')\n",
    "df = df.groupby(['ARR_NAME']).apply(early_pct,'ARR_DELAY','train_arr_early_pct')\n",
    "df = df.groupby(['ARR_NAME','STN_NAME']).apply(early_pct,'ARR_DELAY','stn_train_arr_early_pct')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T02:20:48.752908Z",
     "start_time": "2022-02-17T02:14:02.287202Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def delay_ave(x,var_in,var_out):\n",
    "    #totoal_freq = len(x[var_in])\n",
    "    totoal_freq = len(x[var_in])\n",
    "    totoal_time = ( x[var_in][x[var_in]>0] ).sum()\n",
    "    x[var_out] = totoal_time/totoal_freq\n",
    "    return x\n",
    "\n",
    "def early_ave(x,var_in,var_out):\n",
    "    totoal_freq = len(x[var_in])\n",
    "    totoal_time = ( x[var_in][x[var_in]<0] ).sum()\n",
    "    x[var_out] = abs(totoal_time)/totoal_freq\n",
    "    return x\n",
    "\n",
    "df = df.groupby(['STN_NAME']).apply(delay_ave,'ARR_DELAY','stn_arr_delay_ave')\n",
    "df = df.groupby(['ARR_NAME']).apply(delay_ave,'ARR_DELAY','train_arr_delay_ave')\n",
    "df = df.groupby(['ARR_NAME','STN_NAME']).apply(delay_ave,'ARR_DELAY','stn_train_arr_delay_ave')\n",
    "\n",
    "df = df.groupby(['STN_NAME']).apply(early_ave,'ARR_DELAY','stn_arr_early_ave')\n",
    "df = df.groupby(['ARR_NAME']).apply(early_ave,'ARR_DELAY','train_arr_early_ave')\n",
    "df = df.groupby(['ARR_NAME','STN_NAME']).apply(early_ave,'ARR_DELAY','stn_train_arr_early_ave')\n",
    "\n",
    "df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T02:26:15.021808Z",
     "start_time": "2022-02-17T02:20:48.755059Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df['stn_tdtl_time'] = round(\n",
    "#     (pd.to_datetime(df['DEPART0']) -\n",
    "#      pd.to_datetime(df['ARRIVAL0'])).dt.seconds)  # 图定停站时间 / s\n",
    "df['stn_tdtl_time']=np.where(df['ARRIVAL0']>df['DEPART0'],0,round(\n",
    "    (pd.to_datetime(df['DEPART0']) -\n",
    "     pd.to_datetime(df['ARRIVAL0'])).dt.seconds))\n",
    "# df['STN_SJTL_TIME'] = round(\n",
    "#     (pd.to_datetime(df['CHUFA_TIME']) -\n",
    "#      pd.to_datetime(df['DAODA_TIME'])).dt.seconds)  # 实际停站时间 / s\n",
    "df['STN_SJTL_TIME'] = np.where(df['DAODA_TIME']>df['CHUFA_TIME'],0,round(\n",
    "    (pd.to_datetime(df['CHUFA_TIME']) -\n",
    "     pd.to_datetime(df['DAODA_TIME'])).dt.seconds))  # 实际停站时间 / s\n",
    "df['STN_XS_TIME'] = df['stn_tdtl_time'] - df['STN_SJTL_TIME']  # 站点吸收时间 / s\n",
    "\n",
    "df.sort_values(['STATIS_ID', 'DAODA_TIME'],\n",
    "               inplace=True,\n",
    "               ascending=[True, True])\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df['FORMER_CHUFA_TIME']=datetime.datetime.now()\n",
    "df['FORMER_DEPART1']=datetime.datetime.now()\n",
    "df['FORMER_STN']='深圳'\n",
    "df['FORMER_DPT_DELAY1']=0\n",
    "# df['DAODA_TIME']=df['DAODA_TIME'].astype('datetime64')\n",
    "for i in range(len(df)):\n",
    "    if i==0:\n",
    "        df['FORMER_CHUFA_TIME'].iat[i]=df['DAODA_TIME'].iat[i]\n",
    "        df['FORMER_DEPART1'].iat[i]=df['ARRIVAL0'].iat[i]\n",
    "        df['FORMER_STN'].iat[i]=df['STN_NAME'].iat[i]\n",
    "        df['FORMER_DPT_DELAY1'].iat[i]=df['ARR_DELAY'].iat[i]\n",
    "    else:\n",
    "        if df['STATIS_ID'].iat[i]==df['STATIS_ID'].iat[i-1]:\n",
    "            df['FORMER_CHUFA_TIME'].iat[i]=df['CHUFA_TIME'].iat[i-1]\n",
    "            df['FORMER_DEPART1'].iat[i]=df['DEPART0'].iat[i-1]\n",
    "            df['FORMER_STN'].iat[i]=df['STN_NAME'].iat[i-1]\n",
    "            df['FORMER_DPT_DELAY1'].iat[i]=df['DPT_DELAY'].iat[i-1]\n",
    "        else:\n",
    "            df['FORMER_CHUFA_TIME'].iat[i]=df['DAODA_TIME'].iat[i]\n",
    "            df['FORMER_DEPART1'].iat[i]=df['ARRIVAL0'].iat[i]\n",
    "            df['FORMER_STN'].iat[i]=df['STN_NAME'].iat[i]\n",
    "            df['FORMER_DPT_DELAY1'].iat[i]=df['ARR_DELAY'].iat[i]\n",
    "#             df['FORMER_DPT_DELAY1'].iat[i]=df['ARR_DELAY'].iat[i]\n",
    "# df['FORMER_CHUFA_TIME'] = df['CHUFA_TIME'].shift(1)  # 前站实际出发\n",
    "# df['FORMER_DEPART1'] = df['DEPART0'].shift(1)  # 前站图定出发\n",
    "\n",
    "# df['FORMER_STN'] = df['STN_NAME'].shift(1)  # 上一站\n",
    "# df['FORMER_DPT_DELAY1'] = df['DPT_DELAY'].shift(1)  # *******\n",
    "\n",
    "# df['ID_TMP'] = df['STATIS_ID'].shift(1)\n",
    "# df.loc[\n",
    "#     df['ID_TMP'] != df['STATIS_ID'],\n",
    "#     ['FORMER_CHUFA_TIME', 'FORMER_DEPART1', 'FORMER_STN', 'FORMER_DPT_DELAY1'\n",
    "#      ]] = np.nan\n",
    "\n",
    "\n",
    "df['qujian_tdtl_time'] = round(\n",
    "    (pd.to_datetime(df['ARRIVAL0']) -\n",
    "     pd.to_datetime(df['FORMER_DEPART1'])).dt.seconds)  # 当前区间图定运行\n",
    "df['QUJIAN_SJTL_TIME'] = round(\n",
    "    (pd.to_datetime(df['DAODA_TIME']) -\n",
    "     pd.to_datetime(df['FORMER_CHUFA_TIME'])).dt.seconds)  # 当前区间实际运行\n",
    "df['QUJIAN_XS_TIME'] = df['qujian_tdtl_time'] - df[\n",
    "    'QUJIAN_SJTL_TIME']  # 当前区间吸收\n",
    "\n",
    "# df.drop(columns=['FORMER_CHUFA_TIME', 'FORMER_DEPART1', 'ID_TMP'],\n",
    "#         inplace=True)\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T02:26:16.158163Z",
     "start_time": "2022-02-17T02:26:15.023699Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df=df[df['QUJIAN_SJTL_TIME']<10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T02:26:17.805011Z",
     "start_time": "2022-02-17T02:26:16.159865Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wt=df[df['qujian_tdtl_time']>80000]\n",
    "wt=wt.drop_duplicates(['STATIS_ID'],keep='first')\n",
    "df = df[~df['STATIS_ID'].isin(wt['STATIS_ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-02-16T03:21:06.363Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T02:26:19.944763Z",
     "start_time": "2022-02-17T02:26:17.806729Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['yc']=df['ARR_DELAY']-df['FORMER_DPT_DELAY1']\n",
    "yc=df[df['yc']<=-600]\n",
    "yc=yc.drop_duplicates(['STATIS_ID'],keep='first')\n",
    "df = df[~df['STATIS_ID'].isin(yc['STATIS_ID'])]\n",
    "del df['yc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df[df['STATIS_ID']==21882163.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df[df['QUJIAN_XS_TIME']>df['QUJIAN_SJTL_TIME']]\n",
    "# def get_inital_dealy(df_init):\n",
    "#     df['qc']=df_init['ARRIVAL0']-df_init['former_depart0']\n",
    "# df1 = df.groupby(['STATIS_ID'],as_index=False).progress_apply(get_inital_dealy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # df[(df['ARRIVAL0']-df['former_depart0'])]\n",
    "# # df['ss']=df['ARRIVAL0']-df['former_depart0']\n",
    "# df['ss'] = round(\n",
    "#     (pd.to_datetime(df['ARRIVAL0']) -\n",
    "#      pd.to_datetime(df['FORMER_DEPART1'])).dt.seconds)  # 当前区间图定运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T02:42:38.862257Z",
     "start_time": "2022-02-17T02:26:19.946570Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def qujian_xs_ave(x,var_in,var_out):\n",
    "    #totoal_freq = len(x[var_in])\n",
    "    totoal_freq = len(x[var_in][x[var_in]>0])\n",
    "    totoal_time = ( x[var_in][ (x[var_in]>0) & ( x['FORMER_DPT_DELAY1']>0) ] ).sum()\n",
    "    x[var_out] = totoal_time/totoal_freq\n",
    "    return x\n",
    "\n",
    "def qujian_ks_ave(x,var_in,var_out):\n",
    "    totoal_freq = len(x[var_in][x[var_in]<0])\n",
    "    totoal_time = ( x[var_in][ (x[var_in]<0) & ( x['FORMER_DPT_DELAY1']>0) ] ).sum()\n",
    "    x[var_out] = abs(totoal_time)/totoal_freq\n",
    "    return x\n",
    "\n",
    "def qujian_xs_pct(x,var_in,var_out):\n",
    "    totoal_freq = len(x['FORMER_DPT_DELAY1']>0)\n",
    "    delay_freq = ( (x[var_in]>0) & ( x['FORMER_DPT_DELAY1']>0) ).sum()\n",
    "    x[var_out] = delay_freq/totoal_freq\n",
    "    return x\n",
    "\n",
    "def qujian_ks_pct(x,var_in,var_out):\n",
    "    totoal_freq = len(x['FORMER_DPT_DELAY1']>0)\n",
    "    delay_freq = ( (x[var_in]<0) & ( x['FORMER_DPT_DELAY1']>0) ).sum()\n",
    "    x[var_out] = delay_freq/totoal_freq\n",
    "    return x\n",
    "\n",
    "# 某区间晚点吸收平均时间\n",
    "df = df.groupby(['STN_NAME','FORMER_STN']).apply(qujian_xs_ave,'QUJIAN_XS_TIME','qujian_xs_ave')  \n",
    "# 某车次在某区间晚点吸收平均时间\n",
    "df = df.groupby(['ARR_NAME','STN_NAME','FORMER_STN']).apply(qujian_xs_ave,'QUJIAN_XS_TIME','train_qujian_xs_ave')  \n",
    "#某区间晚点扩散平均时间\n",
    "df = df.groupby(['STN_NAME','FORMER_STN']).apply(qujian_ks_ave,'QUJIAN_XS_TIME','qujian_ks_ave')\n",
    "# 某车次在某区间晚点扩散平均时间\n",
    "df = df.groupby(['ARR_NAME','STN_NAME','FORMER_STN']).apply(qujian_ks_ave,'QUJIAN_XS_TIME','train_qujian_ks_ave')  \n",
    "\n",
    "\n",
    "# 某区间晚点吸收发生概率\n",
    "df = df.groupby(['STN_NAME','FORMER_STN']).apply(qujian_xs_pct,'QUJIAN_XS_TIME','qujian_xs_pct')  \n",
    "# 某车次在某区间晚点吸收发生概率\n",
    "df = df.groupby(['ARR_NAME','STN_NAME','FORMER_STN']).apply(qujian_xs_pct,'QUJIAN_XS_TIME','train_qujian_xs_pct')  \n",
    "#某区间晚点扩散发生概率\n",
    "df = df.groupby(['STN_NAME','FORMER_STN']).apply(qujian_ks_pct,'QUJIAN_XS_TIME','qujian_ks_pct')\n",
    "# 某车次在某区间晚点扩散发生概率\n",
    "df = df.groupby(['ARR_NAME','STN_NAME','FORMER_STN']).apply(qujian_ks_pct,'QUJIAN_XS_TIME','train_qujian_ks_pct')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T02:54:38.559569Z",
     "start_time": "2022-02-17T02:42:38.864430Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def stn_xs_ave(x,var_in,var_out):\n",
    "    #totoal_freq = len(x[var_in])\n",
    "    totoal_freq = len(x[var_in][x[var_in]>0])\n",
    "    totoal_time = ( x[var_in][ (x[var_in]>0) & ( x['ARR_DELAY']>0) ] ).sum()\n",
    "    x[var_out] = totoal_time/totoal_freq\n",
    "    return x\n",
    "\n",
    "def stn_ks_ave(x,var_in,var_out):\n",
    "    totoal_freq = len(x[var_in][x[var_in]<0])\n",
    "    totoal_time = ( x[var_in][ (x[var_in]<0) & ( x['ARR_DELAY']>0) ] ).sum()\n",
    "    x[var_out] = abs(totoal_time)/totoal_freq\n",
    "    return x\n",
    "def stn_xs_pct(x,var_in,var_out):\n",
    "    totoal_freq = len(x['ARR_DELAY']>0)\n",
    "    delay_freq = ( (x[var_in]>0) & ( x['ARR_DELAY']>0) ).sum()\n",
    "    x[var_out] = delay_freq/totoal_freq\n",
    "    return x\n",
    "\n",
    "def stn_ks_pct(x,var_in,var_out):\n",
    "    totoal_freq = len(x['ARR_DELAY']>0)\n",
    "    delay_freq = ( (x[var_in]<0) & ( x['ARR_DELAY']>0) ).sum()\n",
    "    x[var_out] = delay_freq/totoal_freq\n",
    "    return x\n",
    "\n",
    "df = df.groupby(['ARR_NAME','STN_NAME']).apply(stn_xs_ave,'STN_XS_TIME','stn_train_xs_ave') \n",
    "df = df.groupby(['ARR_NAME','STN_NAME']).apply(stn_ks_ave,'STN_XS_TIME','stn_train_ks_ave') \n",
    "\n",
    "df = df.groupby(['ARR_NAME','STN_NAME']).apply(stn_xs_pct,'STN_XS_TIME','stn_train_xs_pct')  \n",
    "df = df.groupby(['ARR_NAME','STN_NAME']).apply(stn_ks_pct,'STN_XS_TIME','stn_train_ks_pct')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def qujian_delay_ave(x,var_in,var_out):\n",
    "#     #totoal_freq = len(x[var_in])\n",
    "#     totoal_freq = len(x[var_in][x[var_in]>0])\n",
    "#     totoal_time = ( x[var_in][ (x[var_in]>0) & ( x['FORMER_DPT_DELAY1']>0) ] ).sum()\n",
    "#     x[var_out] = totoal_time/totoal_freq\n",
    "#     return x\n",
    "\n",
    "# def qujian_early_ave(x,var_in,var_out):\n",
    "#     totoal_freq = len(x[var_in][x[var_in]<0])\n",
    "#     totoal_time = ( x[var_in][ (x[var_in]<0) & ( x['FORMER_DPT_DELAY1']>0) ] ).sum()\n",
    "#     x[var_out] = abs(totoal_time)/totoal_freq\n",
    "#     return x\n",
    "\n",
    "# # 某区间晚点吸收平均时间\n",
    "# df = df.groupby(['STN_NAME','FORMER_STN']).apply(qujian_delay_ave,'QUJIAN_XS_TIME','qujian_xs_ave')  \n",
    "# # 某车次在某区间晚点吸收平均时间\n",
    "# df = df.groupby(['ARR_NAME','STN_NAME','FORMER_STN']).apply(qujian_delay_ave,'QUJIAN_XS_TIME','train_qujian_xs_ave')  \n",
    "# #某区间晚点扩散平均时间\n",
    "# df = df.groupby(['STN_NAME','FORMER_STN']).apply(qujian_early_ave,'QUJIAN_XS_TIME','qujian_ks_ave')\n",
    "# # 某车次在某区间晚点扩散平均时间\n",
    "# df = df.groupby(['ARR_NAME','STN_NAME','FORMER_STN']).apply(qujian_early_ave,'QUJIAN_XS_TIME','train_qujian_ks_ave')  \n",
    "\n",
    "\n",
    "# # 某区间晚点吸收发生概率\n",
    "# df = df.groupby(['STN_NAME','FORMER_STN']).apply(delay_pct,'QUJIAN_XS_TIME','qujian_xs_pct')  \n",
    "# # 某车次在某区间晚点吸收发生概率\n",
    "# df = df.groupby(['ARR_NAME','STN_NAME','FORMER_STN']).apply(delay_pct,'QUJIAN_XS_TIME','train_qujian_xs_pct')  \n",
    "# #某区间晚点扩散发生概率\n",
    "# df = df.groupby(['STN_NAME','FORMER_STN']).apply(early_pct,'QUJIAN_XS_TIME','qujian_ks_pct')\n",
    "# # 某车次在某区间晚点扩散发生概率\n",
    "# df = df.groupby(['ARR_NAME','STN_NAME','FORMER_STN']).apply(early_pct,'QUJIAN_XS_TIME','train_qujian_ks_pct')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T02:54:40.106579Z",
     "start_time": "2022-02-17T02:54:38.562250Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['capacity'] = df.groupby('STN_NAME')['STN_NAME'].transform('count')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# yc=df[df['STN_SJTL_TIME']>df['stn_tdtl_time']]\n",
    "# yc.drop_duplicates('STATIS_ID',keep='first',inplace=True)\n",
    "# yc\n",
    "# df[df['ARR_DELAY'].shift(-1)-df['DPT_DELAY']]\n",
    "# df['former_dep_delay'] = df['CHUFA_TIME'].shift(1)\n",
    "# df['yc'] = round(\n",
    "#     (pd.to_datetime(df['ARR_DELAY']) -\n",
    "#      pd.to_datetime(df['FORMER_DPT_DELAY1'])).dt.seconds)  # 图定停站时间 / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T02:54:49.702860Z",
     "start_time": "2022-02-17T02:54:40.108893Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.sort_values(['STN_NAME','DAODA_TIME'],inplace=True,ascending=[True,True])\n",
    "df.reset_index(drop=True, inplace=True) \n",
    "# df['front_train_arr_delay'] = df['ARR_DELAY'].shift(1)*60  # 前车当前站到达晚点\n",
    "# df['front_train_dpt_delay'] = df['DPT_DELAY'].shift(1)*60 # 前车当前站出发晚点\n",
    "\n",
    "print(df.shape)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T02:54:55.498840Z",
     "start_time": "2022-02-17T02:54:49.704815Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "months = pd.to_datetime(df['DEPART0']).dt.month\n",
    "\n",
    "def assign_seasion(x):\n",
    "    if x <= 3:\n",
    "        return 'Spring'\n",
    "    elif x <= 6:\n",
    "        return 'Summer'\n",
    "    elif x <= 9:\n",
    "        return 'Autumn'\n",
    "    else:\n",
    "        return 'Winter'\n",
    "\n",
    "season = months.progress_apply(assign_seasion)\n",
    "\n",
    "df['Season'] = season\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T02:55:01.179916Z",
     "start_time": "2022-02-17T02:54:55.500361Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "根据DEPART0获取日期，根据日期判断是工作日、休息日、节假日\n",
    "dayofweek,小于4为Weekday（工作日），其他为Weekend（休息日）\n",
    "节假日为法定节假日，优先级高于工作日和休息日\n",
    "\"\"\"\n",
    "\n",
    "dayofweek = pd.to_datetime(df['DEPART0']).dt.dayofweek\n",
    "\n",
    "# 分配工作日、周末\n",
    "def assign_day(x):\n",
    "    if x <= 4:\n",
    "        return 'Weekday'\n",
    "    else:\n",
    "        return 'Weekend'\n",
    "\n",
    "whatday = dayofweek.progress_apply(assign_day)\n",
    "\n",
    "df['WhatDay'] = whatday\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T02:58:33.674020Z",
     "start_time": "2022-02-17T02:55:01.181482Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "holidays = ['01-01', '02-04','02-05','02-06','02-07','02-08','02-09','02-10','04-05',\n",
    "            '05-01','05-02','05-03','05-04','06-07','09-13', '10-01','10-02','10-03','10-04','10-05','10-06','10-07']\n",
    "\n",
    "month_day = pd.to_datetime(df['DEPART0']).dt.strftime('%m-%d')\n",
    "df['MonthDay'] = month_day\n",
    "\n",
    "def assign_holiday(x):\n",
    "    if x['MonthDay'] in holidays:\n",
    "        return 'Holiday'\n",
    "    else:\n",
    "        return x['WhatDay']\n",
    "\n",
    "df.loc[:, \"WhatDay\"] = df.progress_apply(assign_holiday, axis=1)\n",
    "\n",
    "del df['MonthDay']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T02:58:39.752399Z",
     "start_time": "2022-02-17T02:58:33.675916Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hour = pd.to_datetime(df['DEPART0']).dt.hour\n",
    "\n",
    "# 分配时间段\n",
    "def assign_time(x):\n",
    "    if x >= 0 and x < 6:\n",
    "        return 'EarlyMorning'\n",
    "    elif x >= 6 and x < 12:\n",
    "        return 'Morning'\n",
    "    elif x >= 12 and x < 18:\n",
    "        return 'Afternoon'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "what_time = hour.progress_apply(assign_time)\n",
    "\n",
    "df['whattime'] = what_time\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T03:02:48.915716Z",
     "start_time": "2022-02-17T02:58:39.754226Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ARRIVAL0 , DEPART0 , AFTER_ARRIVAL0 , AFTER_DEPART0\n",
    "\"\"\"\n",
    "1.通通:B、C均为行调中间站。（图定到达时间 == 图定出发时间） #标记为1\n",
    "2.发到:B、C均是客运中间站。（图定到达时间 != 图定出发时间） #标记为2\n",
    "2.通到:B是行调中间站,C是客运中间站.(B 图定到达时间==图定出发时间,C图定到达时间!=图定出发时间)#标记为3\n",
    "3.发通:B是客运中间站,C是行调中间站.(B 图定到达时间!=图定出发时间,C图定到达时间==图定出发时间)#标记为3\n",
    "\"\"\"\n",
    "\n",
    "# df['FORMER_ARRIVAL1'] = df['ARRIVAL0'].shift(1)\n",
    "# df['FORMER_DEPART1'] = df['DEPART0'].shift(1)\n",
    "df['FORMER_ARRIVAL1']=datetime.datetime.now()\n",
    "df['FORMER_DEPART1']=datetime.datetime.now()\n",
    "for i in range(len(df)):\n",
    "    if i==0:\n",
    "        df['FORMER_ARRIVAL1'].iat[i] = df['ARRIVAL0'].iat[i]\n",
    "        df['FORMER_DEPART1'].iat[i]=df['ARRIVAL0'].iat[i]\n",
    "    else:\n",
    "        if df['STATIS_ID'].iat[i]==df['STATIS_ID'].iat[i-1]:\n",
    "            df['FORMER_ARRIVAL1'].iat[i] = df['ARRIVAL0'].iat[i-1]\n",
    "            df['FORMER_DEPART1']=df['DEPART0'].iat[i-1]\n",
    "        else:\n",
    "            df['FORMER_ARRIVAL1'].iat[i] = df['ARRIVAL0'].iat[i]\n",
    "            df['FORMER_DEPART1'].iat[i]=df['ARRIVAL0'].iat[i]\n",
    "conditions = [\n",
    "    np.logical_and(df['ARRIVAL0'] == df['DEPART0'],\n",
    "                   df['FORMER_ARRIVAL1'] == df['FORMER_DEPART1']),\n",
    "    np.logical_and(df['ARRIVAL0'] == df['DEPART0'],\n",
    "                   df['FORMER_ARRIVAL1'] != df['FORMER_DEPART1']),\n",
    "    np.logical_and(df['ARRIVAL0'] != df['DEPART0'],\n",
    "                   df['FORMER_ARRIVAL1'] == df['FORMER_DEPART1']),\n",
    "    np.logical_and(df['ARRIVAL0'] != df['DEPART0'],\n",
    "                   df['FORMER_ARRIVAL1'] != df['FORMER_DEPART1']),\n",
    "\n",
    "]\n",
    "\n",
    "choices = ['1', '2', '2', '3']\n",
    "df.loc[:, 'qujian_yx_state'] = np.select(conditions, choices, default='unkown')\n",
    "\n",
    "df.drop(columns=['FORMER_ARRIVAL1', 'FORMER_DEPART1'], inplace=True)\n",
    "print(df.columns)\n",
    "print(df['qujian_yx_state'].value_counts())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T03:03:09.145814Z",
     "start_time": "2022-02-17T03:02:48.917721Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 区间吸收最大值\n",
    "df['qujian_xs_max'] = df.groupby(['STN_NAME','FORMER_STN'])['QUJIAN_XS_TIME'].transform(lambda x: x.max())\n",
    "\n",
    "# 车次区间吸收最大值\n",
    "df['train_qujian_xs_max'] = df.groupby(['STN_NAME','FORMER_STN', 'ARR_NAME'])['QUJIAN_XS_TIME'].transform(lambda x: x.max())\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T03:03:26.545681Z",
     "start_time": "2022-02-17T03:03:09.147863Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 车站吸收最大值\n",
    "df['stn_xs_max'] = df.groupby(['STN_NAME'])['STN_XS_TIME'].transform(lambda x: x.max())\n",
    "\n",
    "# 车次车站吸收最大值\n",
    "df['stn_train_xs_max'] = df.groupby(['STN_NAME','ARR_NAME'])['STN_XS_TIME'].transform(lambda x: x.max())\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T03:05:34.853690Z",
     "start_time": "2022-02-17T03:03:26.547319Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 获取每个行程（即每趟车）的下一站，用于判断前车和后车下一站是否相同\n",
    "df[\"ARRIVAL0\"] = pd.to_datetime(df[\"ARRIVAL0\"], format= \"%Y/%m/%d %H:%M:%S\")\n",
    "df.sort_values(['STATIS_ID', 'DAODA_TIME'], inplace=True, ascending=[True, True])\n",
    "# df['NEXT_STN'] = df['STN_NAME'].shift(-1) # 当前列车下一站\n",
    "df['NEXT_STN']='深圳'\n",
    "for i in range(len(df)):\n",
    "    if i==len(df)-1:\n",
    "        df['NEXT_STN'].iat[i]=df['STN_NAME'].iat[i]\n",
    "    else:\n",
    "        if df['STATIS_ID'].iat[i]==df['STATIS_ID'].iat[i+1]:\n",
    "            df['NEXT_STN'].iat[i]=df['STN_NAME'].iat[i+1]\n",
    "        else:\n",
    "            df['NEXT_STN'].iat[i]=df['STN_NAME'].iat[i]\n",
    "    \n",
    "\n",
    "df.sort_values(['STN_NAME', 'TRACK', 'NEXT_STN', 'DAODA_TIME'], inplace=True, ascending=[True, True, True, True])\n",
    "df.reset_index(drop=True, inplace=True )\n",
    "\n",
    "# df['FORMER_TRAIN'] = df['ARR_NAME'].shift(1)\n",
    "\n",
    "# df['FORMER_TRAIN_NEXT_STN'] = df['NEXT_STN'].shift(1)\n",
    "# df['FORMER_TRAIN_ARRIVAL1'] = df['ARRIVAL0'].shift(1)\n",
    "# df['FORMER_TRAIN'] ='G'\n",
    "# df['FORMER_TRAIN_NEXT_STN']='深圳'\n",
    "# df['FORMER_TRAIN_ARRIVAL1']=datetime.datetime.now()\n",
    "# for i in range(len(df)):\n",
    "#     if i==0:\n",
    "#         df['FORMER_TRAIN'].iat[i]=df['ARR_NAME'].iat[i]\n",
    "#         df['FORMER_TRAIN_NEXT_STN'].iat[i]=df['NEXT_STN'].iat[i]\n",
    "#         df['FORMER_TRAIN_ARRIVAL1'].iat[i]=df['ARRIVAL0'].iat[i]\n",
    "#     else:\n",
    "#         if df['STATIS_ID'].iat[i]==df['STATIS_ID'].iat[i-1]:\n",
    "#             df['FORMER_TRAIN'].iat[i]=df['ARR_NAME'].iat[i-1]\n",
    "#             df['FORMER_TRAIN_NEXT_STN'].iat[i]=df['NEXT_STN'].iat[i-1]\n",
    "#             df['FORMER_TRAIN_ARRIVAL1'].iat[i]=df['ARRIVAL0'].iat[i-1]\n",
    "#         else:\n",
    "#             df['FORMER_TRAIN'].iat[i]=df['ARR_NAME'].iat[i]\n",
    "#             df['FORMER_TRAIN_NEXT_STN'].iat[i]=df['NEXT_STN'].iat[i]\n",
    "#             df['FORMER_TRAIN_ARRIVAL1'].iat[i]=df['ARRIVAL0'].iat[i]\n",
    "# current_time = df['ARRIVAL0']\n",
    "# former_time = df['FORMER_TRAIN_ARRIVAL1']\n",
    "\n",
    "# diff = (current_time - former_time)\n",
    "# diff = diff.fillna(0)\n",
    "# diff = diff.dt.total_seconds().astype(int)\n",
    "# df['arr_diff'] = diff\n",
    "\n",
    "# # 站点/轨道/下一站变化时不是前后车关系\n",
    "# # mask = np.logical_and.reduce((df['STN_NAME'].shift(1) == df['STN_NAME'], \n",
    "# #                               df['TRACK'].shift(1) == df['TRACK'],\n",
    "# #                               df['FORMER_TRAIN_NEXT_STN'].shift(-1) == df['FORMER_TRAIN_NEXT_STN']))\n",
    "\n",
    "# # df['arr_diff'] = np.where(mask, df['arr_diff'], 0)\n",
    "# # df['arr_diff'] = np.where(df['arr_diff'] < 0 , 0, df['arr_diff'])\n",
    "\n",
    "# df.drop(df[['NEXT_STN','FORMER_TRAIN','FORMER_TRAIN_NEXT_STN','FORMER_TRAIN_ARRIVAL1']], axis=1, inplace=True)\n",
    "\n",
    "# print(df.info())\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T03:08:34.369088Z",
     "start_time": "2022-02-17T03:05:34.856228Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df2 = pd.read_csv(os.path.join(gbk_data_path, 'ZM_table_full.csv'))\n",
    "df2 = pd.read_csv('/home/AI/other/ZM_table_full.csv')\n",
    "print(df2.shape)\n",
    "lc_map = {(k1,k2): v for k1, k2, v in df2[['Q_CZM','H_CZM','ZXLC']].values}\n",
    "\n",
    "\n",
    "def assign_lc(x):\n",
    "    k1 = x['FORMER_STN']\n",
    "    k2 = x['STN_NAME']\n",
    "    try:\n",
    "        return lc_map[(k1, k2)]\n",
    "    except:\n",
    "        try: \n",
    "            return lc_map[(k2, k1)]\n",
    "        except:\n",
    "            return 0 \n",
    "\n",
    "df.loc[:, \"DISTANCE\"] = df.progress_apply(assign_lc, axis=1)\n",
    "\n",
    "df['PLAN_SPEED'] = df['DISTANCE'] / df['qujian_tdtl_time'] * 3600\n",
    "\n",
    "print(np.sum((df[\"DISTANCE\"]==0) & (df['FORMER_STN']!=0))/len(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T03:08:34.548057Z",
     "start_time": "2022-02-17T03:08:34.370965Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 异常速度值截断为350km/h\n",
    "df['PLAN_SPEED'] = np.where(df['PLAN_SPEED']>350, 350, df['PLAN_SPEED'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T10:42:38.858784Z",
     "start_time": "2022-02-15T09:36:29.710Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df1=df[df['XM']=='京沪高铁']\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T03:08:42.581036Z",
     "start_time": "2022-02-17T03:08:34.549579Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.sort_values(['STATIS_ID', 'DAODA_TIME'], inplace=True, ascending=[True, True])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T03:08:42.719583Z",
     "start_time": "2022-02-17T03:08:42.582807Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True,drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T03:08:42.731415Z",
     "start_time": "2022-02-17T03:08:42.720956Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_inital_dealy(df_init):\n",
    "    \n",
    "    df_init.reset_index(inplace=True,drop=True)\n",
    "#     print(df_init['STATIS_ID'][0])\n",
    "#     print(df_init.shape)\n",
    "    df_init['seq_id_arr'] = '0'\n",
    "    df_init['seq_id_dpt'] = '0'\n",
    "    arr_delay_list = list(np.where((df_init['ARR_DELAY_TYPE'] == '到达初始晚点'))[0])\n",
    "    arr_delay_list.append(df_init.index[-1])\n",
    "    dpt_delay_list = list(np.where((df_init['DPT_DELAY_TYPE'] == '出发初始晚点'))[0])\n",
    "    dpt_delay_list.append(df_init.index[-1])\n",
    "#     print('arr_delay_list',arr_delay_list)\n",
    "#     print('arr_delay_list',dpt_delay_list)\n",
    "    \n",
    "    if np.sum(arr_delay_list) >= 1:\n",
    "#         判断最后一战是否为初始晚点，避免数据重复\n",
    "#         print('flag', (df_init.iloc[-1]['ARR_DELAY_TYPE'] == '到达初始晚点'))\n",
    "#         if not (df_init.iloc[-1]['ARR_DELAY_TYPE'] == '到达初始晚点'):\n",
    "#             arr_delay_list.append(df_init.index[-1])\n",
    "            \n",
    "#         print('arr_delay_list',arr_delay_list)\n",
    "        for i in range(len(arr_delay_list) - 1):\n",
    "            arr_start_index = arr_delay_list[i]\n",
    "            arr_end_index = arr_delay_list[i + 1]\n",
    "            \n",
    "            empty_seq_arr = df_init.loc[arr_start_index+1:arr_end_index, ['ARR_DELAY_TYPE', 'DPT_DELAY_TYPE']]\n",
    "            arr_end_index_df = empty_seq_arr[((empty_seq_arr['ARR_DELAY_TYPE'] == '到达正点') | (empty_seq_arr['ARR_DELAY_TYPE'] == '早到')) \n",
    "                                             | ((empty_seq_arr['DPT_DELAY_TYPE'] == '出发正点') |  (empty_seq_arr['DPT_DELAY_TYPE'] == '早发'))]\n",
    "#             print('arr_start_index',arr_start_index)\n",
    "#             print('arr_end_index',arr_end_index)\n",
    "#             print('empty_seq_arr',empty_seq_arr)\n",
    "            if not arr_end_index_df.empty:\n",
    "                arr_end_index = arr_end_index_df.index[0]\n",
    "               \n",
    "#             print('arr_end_index',arr_end_index)\n",
    "    \n",
    "            df_init['seq_id_arr'][arr_start_index:arr_end_index+1] = str(uuid.uuid1())\n",
    "            \n",
    "    if np.sum(dpt_delay_list) >= 1:\n",
    "        # 判断最后一战是否为初始晚点，避免数据重复\n",
    "#         if not (df_init.iloc[-1]['DPT_DELAY_TYPE'] == '出发初始晚点'):\n",
    "#             dpt_delay_list.append(df_init.index[-1])\n",
    "#         print('dpt_delay_list',dpt_delay_list)\n",
    "        for i in range(len(dpt_delay_list) - 1):\n",
    "            dpt_start_index = dpt_delay_list[i]\n",
    "            dpt_end_index = dpt_delay_list[i + 1]\n",
    "            \n",
    "            empty_seq_dpt = df_init.loc[dpt_start_index+1:dpt_end_index, ['ARR_DELAY_TYPE', 'DPT_DELAY_TYPE']]\n",
    "            dpt_end_index_df = empty_seq_dpt[((empty_seq_dpt['ARR_DELAY_TYPE'] == '到达正点') | (empty_seq_dpt['ARR_DELAY_TYPE'] == '早到')) \n",
    "                                             | ((empty_seq_dpt['DPT_DELAY_TYPE'] == '出发正点') |  (empty_seq_dpt['DPT_DELAY_TYPE'] == '早发'))]\n",
    "#             print('dpt_start_index',dpt_start_index)\n",
    "#             print('dpt_end_index',dpt_end_index)\n",
    "#             print('empty_seq_dpt',empty_seq_dpt)\n",
    "            if not dpt_end_index_df.empty:\n",
    "                dpt_end_index = dpt_end_index_df.index[0]\n",
    "#             print('dpt_end_index',dpt_end_index)\n",
    "            \n",
    "            df_init['seq_id_dpt'][dpt_start_index:dpt_end_index+1] = str(uuid.uuid1())\n",
    "            \n",
    "    return df_init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T03:20:06.846288Z",
     "start_time": "2022-02-17T03:08:42.732824Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df.groupby(['STATIS_ID'],as_index=False).progress_apply(get_inital_dealy)\n",
    "# get_inital_dealy(df[df['STATIS_ID'] ==  21770071])\n",
    "\n",
    "df = df.groupby(['STATIS_ID'],as_index=False).progress_apply(get_inital_dealy)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df['seq_id_arr'] = df['seq_id_arr'].astype(\"category\")\n",
    "df['seq_id_dpt'] = df['seq_id_dpt'].astype(\"category\")\n",
    "\n",
    "df['seq_id_arr'] = df['seq_id_arr'].cat.rename_categories(range(len(df['seq_id_arr'].unique())))\n",
    "df['seq_id_dpt'] = df['seq_id_dpt'].cat.rename_categories(range(len(df['seq_id_dpt'].unique())))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T03:20:12.656347Z",
     "start_time": "2022-02-17T03:20:06.849467Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "arr=df[(df['seq_id_arr']!=0) & (df['seq_id_arr']!='0')]\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T03:20:12.849429Z",
     "start_time": "2022-02-17T03:20:12.658295Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dpt=df[(df['seq_id_dpt']!=0) & (df['seq_id_dpt']!='0')]\n",
    "dpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T03:20:12.976078Z",
     "start_time": "2022-02-17T03:20:12.850860Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dawandian=arr[(arr['ARR_DELAY_TYPE']=='到达初始晚点') & (arr['ARR_DELAY']>=300) ]['seq_id_arr']\n",
    "print(len(dawandian))\n",
    "dawandian=arr[arr['seq_id_arr'].isin(dawandian)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T03:20:13.119615Z",
     "start_time": "2022-02-17T03:20:12.977802Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dawandian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-02-16T09:03:13.163Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xiao=arr[(arr['ARR_DELAY_TYPE']=='到达初始晚点') & (arr['ARR_DELAY']<300) ]['seq_id_arr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shuju=df[df['seq_id_arr'].isin(xiao)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shuju=shuju[(shuju['ARR_DELAY_TYPE']=='到达连带晚点')|(shuju['DPT_DELAY_TYPE']=='出发连带晚点')]\n",
    "a=shuju[(shuju['ARR_DELAY']>=300)|(shuju['DPT_DELAY']>=300)]['seq_id_arr'].unique()\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xiaowandian=arr[arr['seq_id_arr'].isin(a)]\n",
    "xiaowandian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandian=pd.concat([dawandian,xiaowandian])\n",
    "wandian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "da=wandian[(wandian['ARR_DELAY_TYPE']=='到达初始晚点') &(wandian['ARR_DELAY']>1800)]['seq_id_arr']\n",
    "wandian=wandian[~wandian['seq_id_arr'].isin(da)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T03:20:17.501187Z",
     "start_time": "2022-02-17T03:20:17.399915Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "da=dawandian[(dawandian['ARR_DELAY_TYPE']=='到达初始晚点') &(dawandian['ARR_DELAY']>1800)]['seq_id_arr']\n",
    "wandian=dawandian[~dawandian['seq_id_arr'].isin(da)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# da=wandian[(wandian['ARR_DELAY']>=1620)| (wandian['DPT_DELAY']>=1620)]['seq_id_arr']\n",
    "# wandian=dawandian[~dawandian['seq_id_arr'].isin(da)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T03:20:45.138524Z",
     "start_time": "2022-02-17T03:20:42.505303Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandian.sort_values(['STATIS_ID', 'DAODA_TIME'], inplace=True, ascending=[True, True])\n",
    "wandian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T03:20:45.280229Z",
     "start_time": "2022-02-17T03:20:45.140393Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandian.reset_index(inplace=True,drop=True)\n",
    "wandian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandian[wandian['STN_FLAG']=='1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data=arr[(arr['ARR_DELAY_TYPE']=='到达初始晚点')&( (arr['ARR_DELAY']>=60) & (arr['ARR_DELAY']<=240) )]['seq_id_arr']\n",
    "data=arr[arr['seq_id_arr'].isin(data)]\n",
    "data.sort_values(['STATIS_ID', 'DAODA_TIME'], inplace=True, ascending=[True, True])\n",
    "data.reset_index(inplace=True,drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "qc=data.drop_duplicates(['seq_id_arr'],keep='first')\n",
    "qc=qc['seq_id_arr']\n",
    "lb=[]\n",
    "for i in qc:\n",
    "    sj=data[data['seq_id_arr']==i]\n",
    "    lb.append(len(sj))\n",
    "print(len(lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "qq=data.drop_duplicates(['STATIS_ID'],keep='first')\n",
    "qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data1=arr[(arr['ARR_DELAY_TYPE']=='到达初始晚点')&( (arr['ARR_DELAY']>=300) & (arr['ARR_DELAY']<=600) )]['seq_id_arr']\n",
    "data1=arr[arr['seq_id_arr'].isin(data1)]\n",
    "data1.sort_values(['STATIS_ID', 'DAODA_TIME'], inplace=True, ascending=[True, True])\n",
    "data1.reset_index(inplace=True,drop=True)\n",
    "data1\n",
    "qc1=data1.drop_duplicates(['seq_id_arr'],keep='first')\n",
    "qc1=qc1['seq_id_arr']\n",
    "lb1=[]\n",
    "for i in qc1:\n",
    "    sj=data1[data1['seq_id_arr']==i]\n",
    "    lb1.append(len(sj)) \n",
    "print(len(lb1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data1=arr[(arr['ARR_DELAY_TYPE']=='到达初始晚点')&( (arr['ARR_DELAY']>1800))]['seq_id_arr']\n",
    "data1=arr[arr['seq_id_arr'].isin(data1)]\n",
    "data1.sort_values(['STATIS_ID', 'DAODA_TIME'], inplace=True, ascending=[True, True])\n",
    "data1.reset_index(inplace=True,drop=True)\n",
    "data1\n",
    "qc1=data1.drop_duplicates(['seq_id_arr'],keep='first')\n",
    "qc1=qc1['seq_id_arr']\n",
    "lb1=[]\n",
    "for i in qc1:\n",
    "    sj=data1[data1['seq_id_arr']==i]\n",
    "    lb1.append(len(sj)) \n",
    "print(len(lb1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data2=arr[(arr['ARR_DELAY_TYPE']=='到达初始晚点')&( (arr['ARR_DELAY']>=660) & (arr['ARR_DELAY']<=1800) )]['seq_id_arr']\n",
    "data2=arr[arr['seq_id_arr'].isin(data2)]\n",
    "data2.sort_values(['STATIS_ID', 'DAODA_TIME'], inplace=True, ascending=[True, True])\n",
    "data2.reset_index(inplace=True,drop=True)\n",
    "qc2=data2.drop_duplicates(['seq_id_arr'],keep='first')\n",
    "qc2=qc2['seq_id_arr']\n",
    "lb2=[]\n",
    "for i in qc2:\n",
    "    sj=data2[data2['seq_id_arr']==i]\n",
    "    lb2.append(len(sj)) \n",
    "print(len(lb2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plt.sca(ax1)\n",
    "plt.figure(dpi=150)\n",
    "# plt.xlabel('1-5')\n",
    "s1=pd.Series(np.array(lb))\n",
    "s2=pd.Series(np.array(lb1))\n",
    "s3=pd.Series(np.array(lb2))\n",
    "yes=pd.DataFrame({'1-4':s1,'5-10':s2,'11-30':s3})\n",
    "# plt.subplot(1,1,2)\n",
    "yes.boxplot()\n",
    "# # plt.subplot(2,2,2)\n",
    "# # plt.boxplot(lb1)\n",
    "# # plt.subplot(2,2,3)\n",
    "# # plt.boxplot(lb2)\n",
    "plt.savefig('箱型图.jpg',bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "yes.to_csv('画图.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.xlabel('6-10')\n",
    "# plt.subplot(2,2,1)\n",
    "plt.boxplot(lb1)\n",
    "# plt.subplot(2,2,2)\n",
    "# plt.boxplot(lb1)\n",
    "# plt.subplot(2,2,3)\n",
    "# plt.boxplot(lb2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.xlabel('11-30')\n",
    "# plt.subplot(2,2,1)\n",
    "plt.boxplot(lb2)\n",
    "# plt.subplot(2,2,2)\n",
    "# plt.boxplot(lb1)\n",
    "# plt.subplot(2,2,3)\n",
    "# plt.boxplot(lb2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandian[(wandian['ARRIVAL0']!=wandian['DEPART0'])& (wandian['ARR_DELAY']!=wandian['DPT_DELAY'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandian[wandian['STATIS_ID']==21756007.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "columns=['STATIS_ID','FORMER_DPT_DELAY1','ARR_DELAY','qujian_tdtl_time','QUJIAN_SJTL_TIME','DAODA_TIME','FORMER_CHUFA_TIME']\n",
    "j=wandian[columns]\n",
    "j['xishou']=(j['FORMER_DPT_DELAY1']-j['ARR_DELAY'])\n",
    "j[np.abs(j['xishou'])>300]\n",
    "# [np.abs(j['FORMER_DPT_DELAY1']-j['ARR_DELAY'])>300]\n",
    "# j[j['QUJIAN_SJTL_TIME']>1800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[df['STATIS_ID']==28916877.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "January=wandian[(wandian['ARRIVAL0'].dt.month)==1]\n",
    "January.drop_duplicates('STATIS_ID',keep='first',inplace=True)\n",
    "January=len(January['STATIS_ID'])\n",
    "February=wandian[(wandian['ARRIVAL0'].dt.month)==2]\n",
    "February.drop_duplicates('STATIS_ID',keep='first',inplace=True)\n",
    "February=len(February['STATIS_ID'])\n",
    "March=wandian[(wandian['ARRIVAL0'].dt.month)==3]\n",
    "March.drop_duplicates('STATIS_ID',keep='first',inplace=True)\n",
    "March=len(March['STATIS_ID'])\n",
    "April=wandian[(wandian['ARRIVAL0'].dt.month)==4]\n",
    "April.drop_duplicates('STATIS_ID',keep='first',inplace=True)\n",
    "April=len(April['STATIS_ID'])\n",
    "May=wandian[(wandian['ARRIVAL0'].dt.month)==5]\n",
    "May.drop_duplicates('STATIS_ID',keep='first',inplace=True)\n",
    "May=len(May['STATIS_ID'])\n",
    "June=wandian[(wandian['ARRIVAL0'].dt.month)==6]\n",
    "June.drop_duplicates('STATIS_ID',keep='first',inplace=True)\n",
    "June=len(June['STATIS_ID'])\n",
    "July=wandian[(wandian['ARRIVAL0'].dt.month)==7]\n",
    "July.drop_duplicates('STATIS_ID',keep='first',inplace=True)\n",
    "July=len(July['STATIS_ID'])\n",
    "August=wandian[(wandian['ARRIVAL0'].dt.month)==8]\n",
    "August.drop_duplicates('STATIS_ID',keep='first',inplace=True)\n",
    "August=len(August['STATIS_ID'])\n",
    "September=wandian[(wandian['ARRIVAL0'].dt.month)==9]\n",
    "September.drop_duplicates('STATIS_ID',keep='first',inplace=True)\n",
    "September=len(September['STATIS_ID'])\n",
    "October=wandian[(wandian['ARRIVAL0'].dt.month)==10]\n",
    "October.drop_duplicates('STATIS_ID',keep='first',inplace=True)\n",
    "October=len(October['STATIS_ID'])\n",
    "November=wandian[(wandian['ARRIVAL0'].dt.month)==11]\n",
    "November.drop_duplicates('STATIS_ID',keep='first',inplace=True)\n",
    "November=len(November['STATIS_ID'])\n",
    "December=wandian[(wandian['ARRIVAL0'].dt.month)==12]\n",
    "December.drop_duplicates('STATIS_ID',keep='first',inplace=True)\n",
    "December=len(December['STATIS_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "month=[January,February,March,April,May,June,July,August,September,October,November,December]\n",
    "month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "name=['1','2','3','4','5','6','7','8','9','10','11','12']\n",
    "plt.bar(name,month,color='rgby')\n",
    "for a,b in zip(name,month):\n",
    "    plt.text(a,b,'%.0f' % b,ha='center',va='bottom',fontsize=11)\n",
    "    \n",
    "plt.savefig(\"沪蓉月\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "one=wandian[((wandian['ARRIVAL0'].dt.hour)>=6) & ((wandian['ARRIVAL0'].dt.hour)<=11)]\n",
    "one.drop_duplicates('STATIS_ID',keep='first',inplace=True)\n",
    "one=len(one['STATIS_ID'])\n",
    "\n",
    "two=wandian[((wandian['ARRIVAL0'].dt.hour)>=12) & ((wandian['ARRIVAL0'].dt.hour)<=17)]\n",
    "two.drop_duplicates('STATIS_ID',keep='first',inplace=True)\n",
    "two=len(two['STATIS_ID'])\n",
    "\n",
    "three=wandian[((wandian['ARRIVAL0'].dt.hour)>=18) & ((wandian['ARRIVAL0'].dt.hour)<=24)]\n",
    "three.drop_duplicates('STATIS_ID',keep='first',inplace=True)\n",
    "three=len(three['STATIS_ID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hour=[one,two,three]\n",
    "\n",
    "name=['6-11','12-17','18-24']\n",
    "plt.bar(name,hour,color='rgby',width=0.4)\n",
    "for a,b in zip(name,hour):\n",
    "    plt.text(a,b,'%.0f' % b,ha='center',va='bottom',fontsize=11)\n",
    "    \n",
    "plt.savefig(\"沪蓉小时\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[df['seq_id_arr'].isin(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(arr['STATIS_ID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandian.drop_duplicates('seq_id_arr',keep='first',inplace=True)\n",
    "wandian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dpt=df[df['seq_id_dpt']!=0]\n",
    "dpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandian[((wandian['ARR_DELAY']>=300)&(wandian['ARR_DELAY']<=1800)) & (wandian['ARR_DELAY_TYPE']=='到达初始晚点')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dawandian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(dpt[(dpt['DPT_DELAY_TYPE']=='出发初始晚点') & (dpt['DPT_DELAY']>=300) ]['seq_id_dpt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xiao1=dpt[(dpt['DPT_DELAY_TYPE']=='出发初始晚点') & (dpt['DPT_DELAY']<300) ]['seq_id_dpt']\n",
    "len(xiao1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shuju1=df[df['seq_id_dpt'].isin(xiao1)]\n",
    "shuju1=shuju1[(shuju1['ARR_DELAY_TYPE']=='到达连带晚点')|(shuju1['DPT_DELAY_TYPE']=='出发连带晚点')]\n",
    "b=shuju1[(shuju1['ARR_DELAY']>=300)|(shuju1['DPT_DELAY']>=300)]['seq_id_dpt'].unique()\n",
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[~df['seq_id_dpt'].isin(b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(dpt['STATIS_ID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "origin2[origin2['STATIS_ID']==21759209.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dpt[dpt['STATIS_ID']==21759209.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dpt[dpt['STATIS_ID']==21773781.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df=df[df['seq_id_arr']!=0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(gbk_data_path+'/2020_ARR_xulie.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-02-17T03:29:25.982Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandian.to_csv('2020_ARR_hkdwandian.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['ARRIVAL1'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['ARRIVAL1'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "arr.to_csv(gbk_data_path+'/2020_jh_jz.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[df['STATIS_ID']==26439803.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ID['LAST_DPT_DELAY'] = ID['DPT_DELAY1'].shift(1)\n",
    "ID['LAST_DPT_DELAY'] = np.where(ID['STATIS_ID'].shift(1) == ID['STATIS_ID'], ID['LAST_DPT_DELAY'], 0)  # 始发站上一站出发晚点时间置0\n",
    "ID['ARR_DELAY1_type']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_inital_dealy(df_init):\n",
    "    arr = list(np.where((df_init['ARR_DELAY1']>4))[0])\n",
    "    dpt = list(np.where((df_init['DPT_DELAY1']>4))[0])\n",
    "    for i in range(len(df_init)):\n",
    "        if df_init['ARR_DELAY1']>4:\n",
    "            df_init['ARR_DELAY1_type']='到达初始晚点'\n",
    "#         df_init['ARR_DELAY1_type'].iloc[arr]='到达初始晚点'\n",
    "#         if  df_init['ARR_DELAY1']<=4:\n",
    "#              df_init['ARR_DELAY1_type']='到达正点'\n",
    "        \n",
    "    print(df_init['ARR_DELAY1_type'])    \n",
    "origin1 = ID.groupby(['STATIS_ID'], as_index=False).progress_apply(get_inital_dealy)\n",
    "origin1.reset_index(drop=True,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 构建\"上一站出发晚点时间\"字段\n",
    "df['LAST_DPT_DELAY'] = df['DPT_DELAY1'].shift(1)\n",
    "df['LAST_DPT_DELAY'] = np.where(df['STATIS_ID'].shift(1) == df['STATIS_ID'], df['LAST_DPT_DELAY'], 0)  # 始发站上一站出发晚点时间置0\n",
    "\n",
    "# 构建\"到达晚点类型\"字段\n",
    "conditions = [df['ARR_DELAY1'] <= 4,df['ARR_DELAY1'] > 4]\n",
    "choices = ['到达正点','到达初始晚点']  # 先将晚点全部设为初始晚点，后续再部分更新为连带晚点\n",
    "df['ARR_DELAY_TYPE'] = np.select(conditions, choices, default='unkown')\n",
    "\n",
    "# 构建\"出发晚点类型\"字段\n",
    "conditions = [df['DPT_DELAY1'] <= 4, df['DPT_DELAY1'] > 4]\n",
    "choices = ['出发正点','出发初始晚点']\n",
    "df['DPT_DELAY_TYPE'] = np.select(conditions, choices, default='unkown')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}